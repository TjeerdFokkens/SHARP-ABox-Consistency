import pyactr as actr
import pandas as pd
import sys
import os
import matplotlib.pyplot as plt
import numpy as np
import Module1 as md1
import Module2 as md2
import Module3 as md3
import Module4 as md4
import Module5 as md5
import parser as par
from matplotlib import colors
from matplotlib.ticker import PercentFormatter
import re
from matplotlib.ticker import MaxNLocator
from collections import Counter
from scipy import stats
import matplotlib as mpl
import matplotlib.gridspec as grid_spec
from sklearn.neighbors import KernelDensity
import matplotlib.patches as patches

dat = pd.read_csv('/Users/xfoktj/Documents/GitHub/ABox-Consistency/data/data12.csv')
sam_num = dat['ABox'].nunique()

def lowerr(sam1, sam2):
    #For every value in sam1, count how many values in sam2 are strictly smaller.
    li1=[]
    for i in sam1:
        v = len(list(x for x in sam2 if x < i))
        li1.append(v)
    return li1

def samee(sam1, sam2):
    #For every value in sam1, count how many values are equally large.
    li2=[]
    for i in sam1:
        v = len(list(x for x in sam2 if x == i))
        li2.append(v)
    return li2

def A_w(sam1, sam2):
    #Calculate the probability of superiority.
    l = lowerr(sam1,sam2)
    s = samee(sam1,sam2)
    numerator = sum(l)+0.5*sum(s)
    denominator = sam1.nunique() * sam2.nunique()
    fraction = numerator/denominator
    return round(fraction,3)

def cohens_d(sample1,sample2):
    s1 = sample1.std()
    s2 = sample2.std()
    s = np.sqrt((s1**2 + s2**2)/2)
    m1 = sample1.mean()
    m2 = sample2.mean()
    d = (m2-m1)/s
    return round(d,3)

#The primary statistics:
def stat_primary(df,abox):
    print('For the ABox ', abox, ' we get the following.')
    dat = df.loc[lambda df1: df1['ABox']==abox, :]
    time_min = dat['Time'].min()
    print('The minimum time:',round(time_min,3))
    time_avg = dat['Time'].mean()
    print('The average time:',round(time_avg,3))
    time_max = dat['Time'].max()
    print('The maximum time:',round(time_max,3))
    run_efficient = dat[dat['Time']==time_min]['Run'].values[0]
    print('The most efficient run:',run_efficient)
    time_average_efficient = dat[dat['Run']==run_efficient]['Time'].mean()
    print('Average time of the most efficient run:',round(time_average_efficient,3))
    run_leastefficient = dat[dat['Time']==time_max]['Run'].values[0]
    print('The least efficient run:',run_leastefficient)
    print('The probability of superiority between most and least efficient:',A_w(dat[dat['Run']==run_efficient]['Time'], dat[dat['Run']==run_leastefficient]['Time']))
    print('')

for sam in dat['ABox'].unique():
    stat_primary(dat,sam)

def compare(abox1,abox2,dat):
    sam1 = dat[dat['ABox']==abox1]['Time']
    sam2 = dat[dat['ABox']==abox2]['Time']
    Aw = A_w(sam1, sam2)
    print('The probability of superiority of ', abox1, ' over ', abox2, ' is: ',Aw)
    d = cohens_d(sam1,sam2)
    print('The effect size in terms of Cohens d: ', d)
    diff = sam2.mean()-sam1.mean()
    print('The absolute difference of the means: ', round(diff,3))
    print('The relative difference of the means (compared to first sample): ', round((diff/sam1.mean())*100,1),'%')

compare(dat['ABox'].unique()[0],dat['ABox'].unique()[1], dat)


#Determining the minimum and maximum x values of the graph.
lx=dat['Time'].min() * 0.7 #the left x limit
rx=dat['Time'].max() * 1.15 #the right x limit

#Defining the colours
colors = [mpl.cm.viridis(i) for i in np.linspace(0,1,10)]

gs = grid_spec.GridSpec(sam_num,1)
fig = plt.figure(figsize=(10,6))

y_max=0
x_d = np.linspace(lx,rx, 1000)
logprob = []

bandwidth = 0.05

for sam in dat['ABox'].unique():
    kde = KernelDensity(bandwidth=bandwidth, kernel='gaussian')
    kde.fit(np.array(dat[dat['ABox']==sam]['Time'])[:,None])
    plot_log_data = kde.score_samples(x_d[:, None])
    plot_data = np.exp(plot_log_data)
    logprob.append(plot_data)
    y_max = max(y_max,max(plot_data))

y_max = y_max * 1.10
ax_objs = []
i = 0
dict = {}

for sam in dat['ABox'].unique():

    ax_objs.append(fig.add_subplot(gs[i:i+1, 0:]))
    # plotting the distribution
    ax_objs[-1].plot(x_d, np.array(logprob[i]),color="#f0f0f0",lw=0.5)
    ax_objs[-1].fill_between(x_d, logprob[i], alpha=1,color=colors[i+2])

    # setting uniform x and y lims
    ax_objs[-1].set_xlim(lx,rx)
    ax_objs[-1].set_ylim(0,y_max)

    # make background transparent
    rect = ax_objs[-1].patch
    rect.set_alpha(0)

    # remove borders, axis ticks, and labels
    ax_objs[-1].set_yticklabels([])
    ax_objs[-1].yaxis.set_visible(False)

    if i == sam_num-1:
        ax_objs[-1].set_xlabel("Inference time (s)", fontsize=14,fontweight="bold")
    else:
        ax_objs[-1].set_xticklabels([])

    spines = ["top","right","left","bottom"]
    for s in spines:
        ax_objs[-1].spines[s].set_visible(False)

    st = 'ABox {}'.format(i)
    ax_objs[-1].text(lx-0.02,0,st,fontweight="bold",fontsize=10,ha="right")
    dict[st] = sam

    i += 1

gs.update(hspace=-0.6)
fig.text(0.07,0.85,"Distribution of inference times",fontsize=18)
j = 0
for i in dict.keys():
    st = i + ': ' + dict[i]
    fig.text(0.8,0.8-0.03*j, st,fontsize=9, horizontalalignment='left', verticalalignment='top')
    j += 1

fig.patches.extend([plt.Rectangle((0.78,0.81-(sam_num + 1)*0.03),0.25,0.5,fill=True, color='grey', alpha=0.3, zorder=1000,transform=fig.transFigure, figure=fig)])

plt.show()

title = 'RoleNameIndependence'
#plt.savefig(title, transparent=True, dpi=1200)
