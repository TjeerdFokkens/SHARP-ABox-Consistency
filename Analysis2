import pyactr as actr
import pandas as pd
import sys
import os
import matplotlib.pyplot as plt
import numpy as np
import Module1 as md1
import Module2 as md2
import Module3 as md3
import Module4 as md4
import Module5 as md5
import parser as par
from matplotlib import colors
from matplotlib.ticker import PercentFormatter
import re
from matplotlib.ticker import MaxNLocator
from collections import Counter
from scipy import stats
import matplotlib as mpl
import matplotlib.gridspec as grid_spec
from sklearn.neighbors import KernelDensity

dat = pd.read_csv('data1.csv')
column_numbers = len(dat.columns)

def lowerr(sam1, sam2):
    #For every value in sam1, count how many values in sam2 are strictly smaller.
    li1=[]
    for i in sam1:
        v = len(list(x for x in sam2 if x < i))
        li1.append(v)
    return li1

def samee(sam1, sam2):
    #For every value in sam1, count how many values are equally large.
    li2=[]
    for i in sam1:
        v = len(list(x for x in sam2 if x == i))
        li2.append(v)
    return li2

def A_w(sam1, sam2):
    #Calculate the probability of superiority.
    l = lowerr(sam1,sam2)
    s = samee(sam1,sam2)
    numerator = sum(l)+0.5*sum(s)
    denominator = len(sam1) * len(sam2)
    fraction = numerator/denominator
    return fraction

#The primary statistics:
def stat_primary(df,abox):
    dat = df.loc[lambda df1: df1['ABox']==abox, :]
    time_min = dat['Time'].min()
    print('The minimum time:',time_min)
    time_avg = dat['Time'].mean()
    print('The average time:',time_avg)
    time_max = dat['Time'].max()
    print('The maximum time:',time_max)
    run_efficient = dat[dat['Time']==time_min]['Run'].values[0]
    print('The most efficient run:',run_efficient)
    time_average_efficient = dat[dat['Run']==run_efficient]['Time'].mean()
    print('Average time of the most efficient run:',time_average_efficient)
    run_leastefficient = dat[dat['Time']==time_max]['Run'].values[0]
    print('The least efficient run:',run_leastefficient)
    print('The probability of superiority between most and least efficient:',A_w(dat[dat['Run']==run_efficient]['Time'], dat[dat['Run']==run_leastefficient]['Time']))

stat_primary(dat,'a:A, (b,a):r, b:/Ar.E')
stat_primary(dat,'a:A, (b,a):r, b:/Ar.-A')


'''
#Determining the minimum and maximum x values of the graph.
min_value = 0.9 *
max_value = 0
for (columnName, columnData) in dat.iteritems():
    times = [x[0] for x in columnData]
    min_value = min(min(times), min_value)
    max_value = max(max_value,max(times))
lx=min_value * 0.9 #the left x limit
rx=max_value * 1.1 #the right x limit


#Defining the colours
color_map = mpl.cm.viridis
pick = list(np.linspace(0,1,column_numbers))
colors = []
for i in pick:
    colors.append(color_map(i))

gs = grid_spec.GridSpec(column_numbers,1)
fig = plt.figure(figsize=(10,6))

y_max=0
x_d = np.linspace(lx,rx, 1000)
logprob = []

for (columnName, columnData) in dat.iteritems():
    times = [x[0] for x in columnData]
    kde = KernelDensity(bandwidth=0.09, kernel='gaussian')
    kde.fit(times[:,None])
    plot_log_data = kde.score_samples(x_d[:, None])
    plot_data = np.exp(plot_log_data)
    logprob.append(plot_data)
    y_max = max(y_max,max(plot_data))

y_max = y_max * 1.05

ax_objs = []
i = 0
for (columnName, columnData) in dat.iteritems():

    ax_objs.append(fig.add_subplot(gs[i:i+1, 0:]))
    # plotting the distribution
    ax_objs[-1].plot(x_d, np.array(logprob[i]),color="#f0f0f0",lw=0.5)
    ax_objs[-1].fill_between(x_d, logprob[i], alpha=1,color=colors[i])

    # setting uniform x and y lims
    ax_objs[-1].set_xlim(lx,rx)
    ax_objs[-1].set_ylim(0,y_max)

    # make background transparent
    rect = ax_objs[-1].patch
    rect.set_alpha(0)

    # remove borders, axis ticks, and labels
    ax_objs[-1].set_yticklabels([])
    ax_objs[-1].yaxis.set_visible(False)

    if i == len(vars)-1:
        ax_objs[-1].set_xlabel("Inference time (s)", fontsize=14,fontweight="bold")
    else:
        ax_objs[-1].set_xticklabels([])

    spines = ["top","right","left","bottom"]
    for s in spines:
        ax_objs[-1].spines[s].set_visible(False)

    adj_var = var.replace("_"," ")
    ax_objs[-1].text(lx-0.02,0,adj_var,fontweight="bold",fontsize=10,ha="right")


    i += 1

gs.update(hspace=-0.6)

fig.text(0.07,0.85,"Distribution inference times for three different runs",fontsize=18)

plt.tight_layout()
plt.show()
'''
